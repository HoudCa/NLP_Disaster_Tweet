{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-20T12:26:17.303070Z","iopub.execute_input":"2022-07-20T12:26:17.303494Z","iopub.status.idle":"2022-07-20T12:26:17.314399Z","shell.execute_reply.started":"2022-07-20T12:26:17.303461Z","shell.execute_reply":"2022-07-20T12:26:17.312827Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install pycodestyle\n!pip install --index-url https://test.pypi.org/simple/ nbpep8","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:32.097335Z","iopub.execute_input":"2022-07-20T11:42:32.097985Z","iopub.status.idle":"2022-07-20T11:42:53.143291Z","shell.execute_reply.started":"2022-07-20T11:42:32.097950Z","shell.execute_reply":"2022-07-20T11:42:53.142043Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"from nbpep8.nbpep8 import pep8","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.146098Z","iopub.execute_input":"2022-07-20T11:42:53.146508Z","iopub.status.idle":"2022-07-20T11:42:53.156548Z","shell.execute_reply.started":"2022-07-20T11:42:53.146468Z","shell.execute_reply":"2022-07-20T11:42:53.155496Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import callbacks, models, layers\nimport matplotlib.pyplot as plt\n\n# tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import confusion_matrix,f1_score,classification_report","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:26:26.594950Z","iopub.execute_input":"2022-07-20T12:26:26.595423Z","iopub.status.idle":"2022-07-20T12:26:36.228871Z","shell.execute_reply.started":"2022-07-20T12:26:26.595374Z","shell.execute_reply":"2022-07-20T12:26:36.227305Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:26:38.328795Z","iopub.execute_input":"2022-07-20T12:26:38.329880Z","iopub.status.idle":"2022-07-20T12:26:38.434648Z","shell.execute_reply.started":"2022-07-20T12:26:38.329816Z","shell.execute_reply":"2022-07-20T12:26:38.433116Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.235604Z","iopub.execute_input":"2022-07-20T11:42:53.235889Z","iopub.status.idle":"2022-07-20T11:42:53.253937Z","shell.execute_reply.started":"2022-07-20T11:42:53.235864Z","shell.execute_reply":"2022-07-20T11:42:53.251768Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.256055Z","iopub.execute_input":"2022-07-20T11:42:53.256663Z","iopub.status.idle":"2022-07-20T11:42:53.270944Z","shell.execute_reply.started":"2022-07-20T11:42:53.256626Z","shell.execute_reply":"2022-07-20T11:42:53.270051Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.272244Z","iopub.execute_input":"2022-07-20T11:42:53.272808Z","iopub.status.idle":"2022-07-20T11:42:53.287116Z","shell.execute_reply.started":"2022-07-20T11:42:53.272770Z","shell.execute_reply":"2022-07-20T11:42:53.286184Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.290096Z","iopub.execute_input":"2022-07-20T11:42:53.290447Z","iopub.status.idle":"2022-07-20T11:42:53.301978Z","shell.execute_reply.started":"2022-07-20T11:42:53.290420Z","shell.execute_reply":"2022-07-20T11:42:53.300906Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"sentiment_counts = train.groupby(['target']).size()\nprint(sentiment_counts)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.303483Z","iopub.execute_input":"2022-07-20T11:42:53.304221Z","iopub.status.idle":"2022-07-20T11:42:53.315186Z","shell.execute_reply.started":"2022-07-20T11:42:53.304185Z","shell.execute_reply":"2022-07-20T11:42:53.314161Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = 'target', data = train, palette = 'Set3')\nplt.xticks(ticks = [0,1], labels = ['Disaster','Non-Disaster'])\nplt.ylabel(\"Count\")\nplt.xlabel(\"Target\")\nplt.title(\"Distribution of target label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.321378Z","iopub.execute_input":"2022-07-20T11:42:53.322179Z","iopub.status.idle":"2022-07-20T11:42:53.468213Z","shell.execute_reply.started":"2022-07-20T11:42:53.322144Z","shell.execute_reply":"2022-07-20T11:42:53.467182Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n \n# Wordcloud with positive tweets\npositive_tweets = train['text'][train[\"target\"] == 1]\nstop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\npositive_wordcloud = WordCloud(max_font_size=50, max_words=50,\\\n                               background_color=\"white\", stopwords = stop_words). \\\ngenerate(str(positive_tweets))\nplt.figure()\nplt.title(\"Non_Disaster Tweets - Wordcloud\")\nplt.imshow(positive_wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n \n# Wordcloud with negative tweets\nnegative_tweets = train['text'][train[\"target\"] == 0]\nstop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\nDisaster_wordcloud = WordCloud(max_font_size=50, max_words=50, \\\n                               background_color=\"white\", stopwords = stop_words). \\\ngenerate(str(negative_tweets))\nplt.figure()\nplt.title(\"Disaster Tweets - Wordcloud\")\nplt.imshow(Disaster_wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.472840Z","iopub.execute_input":"2022-07-20T11:42:53.475728Z","iopub.status.idle":"2022-07-20T11:42:53.964559Z","shell.execute_reply.started":"2022-07-20T11:42:53.475671Z","shell.execute_reply":"2022-07-20T11:42:53.963673Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"def missing_values(df):\n    nb_missing = df.isnull().sum()\n    percent_missing = 100 * df.isnull().sum() / len(df)\n    missing_table = pd.concat([nb_missing, percent_missing], axis=1,\n                              keys=['Nb of missing values', '% of missing values'])\n    missing_table_sorted = missing_table[\n        missing_table.iloc[:, 1] != 0].sort_values(\n        '% of missing values', ascending=False).round(2)\n    \n    return missing_table_sorted\n\nmissing_values(train)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:53.966001Z","iopub.execute_input":"2022-07-20T11:42:53.966999Z","iopub.status.idle":"2022-07-20T11:42:53.999654Z","shell.execute_reply.started":"2022-07-20T11:42:53.966963Z","shell.execute_reply":"2022-07-20T11:42:53.998512Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"missing_values(test)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:54.005044Z","iopub.execute_input":"2022-07-20T11:42:54.007778Z","iopub.status.idle":"2022-07-20T11:42:54.024422Z","shell.execute_reply.started":"2022-07-20T11:42:54.007737Z","shell.execute_reply":"2022-07-20T11:42:54.023408Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\ndef feature_viz(df,feature):\n    \n    '''Input- df=pandas dataframe\n              feature= column to be charted\n       Output- bar and scatter chart using plotly       \n    \n    '''\n    #Visualize the feature\n    if feature=='target':\n        sns.countplot(feature, data=df)\n        print('Target of 0 is {} % of total'.format(round(df[feature].value_counts()[0]/len(df[feature])*100)))\n        print('Target of 1 is {} % of total'.format(round(df[feature].value_counts()[1]/len(df[feature])*100)))\n    else:\n        #Distinct keywords in train dataset\n        feat=df[feature].value_counts()\n        print(feat.head())\n        fig = px.scatter(feat, x=feat.values, y=feat.index,size=feat.values)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:54.025613Z","iopub.execute_input":"2022-07-20T11:42:54.026553Z","iopub.status.idle":"2022-07-20T11:42:56.059245Z","shell.execute_reply.started":"2022-07-20T11:42:54.026515Z","shell.execute_reply":"2022-07-20T11:42:56.058222Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"feature_viz(train, 'keyword')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:56.060500Z","iopub.execute_input":"2022-07-20T11:42:56.060869Z","iopub.status.idle":"2022-07-20T11:42:56.858759Z","shell.execute_reply.started":"2022-07-20T11:42:56.060834Z","shell.execute_reply":"2022-07-20T11:42:56.857670Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"train['text_length'] = train['text'].apply(lambda x : len(x.split(' ')))\n#Create visualization of the distribution of text length in comparision to target feature\nf, (ax1, ax2) = plt.subplots(1, 2, sharex=True,figsize=(10,6))\nsns.histplot(train[(train['target'] == 1)]['text_length'], ax=ax1, kde=False, color='red',label='Disater Tweets')\nsns.histplot(train[(train['target'] == 0)]['text_length'],ax=ax2, kde=False, color='green',label='Non-Disater Tweets');\nf.suptitle('Tweet length distribution')\nf.legend(loc='upper right')\nax1.grid()\nax2.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:41:33.563770Z","iopub.execute_input":"2022-07-20T12:41:33.564211Z","iopub.status.idle":"2022-07-20T12:41:34.233235Z","shell.execute_reply.started":"2022-07-20T12:41:33.564180Z","shell.execute_reply":"2022-07-20T12:41:34.229918Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train['length'] = train['text'].apply(lambda x : len(x.split(' ')))\ntrain['length'].max()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:40:58.702734Z","iopub.execute_input":"2022-07-20T12:40:58.703169Z","iopub.status.idle":"2022-07-20T12:40:58.731845Z","shell.execute_reply.started":"2022-07-20T12:40:58.703137Z","shell.execute_reply":"2022-07-20T12:40:58.730446Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstop_words = stopwords.words(\"english\")\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:57.274968Z","iopub.execute_input":"2022-07-20T11:42:57.275414Z","iopub.status.idle":"2022-07-20T11:42:57.284587Z","shell.execute_reply.started":"2022-07-20T11:42:57.275374Z","shell.execute_reply":"2022-07-20T11:42:57.283664Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"stemmer = SnowballStemmer('english')\ndef clean_text(each_text):\n    clean_html = BeautifulSoup(each_text).get_text()\n\n    # remove URL from text\n    #each_text_no_url = re.sub(r\"http\\S+\", \"\", clean_html)\n    \n    # remove numbers from text\n    text_no_num = re.sub(r'\\d+', '', clean_html)\n\n    # tokenize each text\n    word_tokens = word_tokenize(text_no_num)\n    \n    # remove sptial character\n    clean_text = []\n    for word in word_tokens:\n        clean_text.append(\"\".join([e for e in word if e.isalnum()]))\n\n    # remove stop words and lower\n    text_with_no_stop_word = [w.lower() for w in clean_text if not w in stop_words]  \n\n    # do stemming\n    stemmed_text = [stemmer.stem(w) for w in text_with_no_stop_word]\n    \n    return \" \".join(\" \".join(stemmed_text).split())\n","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:57.286168Z","iopub.execute_input":"2022-07-20T11:42:57.286589Z","iopub.status.idle":"2022-07-20T11:42:57.296871Z","shell.execute_reply.started":"2022-07-20T11:42:57.286553Z","shell.execute_reply":"2022-07-20T11:42:57.295826Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"train[\"cleaned_text\"] = train[\"text\"].apply(clean_text)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:42:57.298687Z","iopub.execute_input":"2022-07-20T11:42:57.298975Z","iopub.status.idle":"2022-07-20T11:43:03.234383Z","shell.execute_reply.started":"2022-07-20T11:42:57.298952Z","shell.execute_reply":"2022-07-20T11:43:03.233389Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"train[\"keyword_1\"] = train[\"keyword\"].fillna(\"none\")\ntrain[\"cleaned_keyword\"] = train[\"keyword_1\"].apply(clean_text)\ntrain[\"cleaned_keyword\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:03.235989Z","iopub.execute_input":"2022-07-20T11:43:03.236376Z","iopub.status.idle":"2022-07-20T11:43:05.825814Z","shell.execute_reply.started":"2022-07-20T11:43:03.236340Z","shell.execute_reply":"2022-07-20T11:43:05.824693Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"# Combine column 'clean_keyword' and 'clean_text' into one\ntrain['keyword_text'] = train['cleaned_keyword'] + \" \" + train[\"cleaned_text\"]\ntrain['keyword_text']","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:05.827527Z","iopub.execute_input":"2022-07-20T11:43:05.827918Z","iopub.status.idle":"2022-07-20T11:43:05.839200Z","shell.execute_reply.started":"2022-07-20T11:43:05.827881Z","shell.execute_reply":"2022-07-20T11:43:05.838231Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install pytorch-transformers\n# Import des librairies\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom transformers import *\nimport time\n# tf.compat.v1.disable_eager_execution()\npath = \"/content/\"\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:27:10.475264Z","iopub.execute_input":"2022-07-20T12:27:10.476402Z","iopub.status.idle":"2022-07-20T12:27:58.232858Z","shell.execute_reply.started":"2022-07-20T12:27:10.476367Z","shell.execute_reply":"2022-07-20T12:27:58.231098Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tweets_raw = train['text']\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:28:34.209911Z","iopub.execute_input":"2022-07-20T12:28:34.211053Z","iopub.status.idle":"2022-07-20T12:28:34.225113Z","shell.execute_reply.started":"2022-07-20T12:28:34.211003Z","shell.execute_reply":"2022-07-20T12:28:34.223655Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tweet_raw_train, tweet_raw_test, y_train, y_test = train_test_split(\n    tweets_raw.values, y,\n    test_size=0.2,\n    stratify=y,\n    random_state=7\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:28:38.355005Z","iopub.execute_input":"2022-07-20T12:28:38.355442Z","iopub.status.idle":"2022-07-20T12:28:38.373188Z","shell.execute_reply.started":"2022-07-20T12:28:38.355408Z","shell.execute_reply":"2022-07-20T12:28:38.371671Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_label = y_train\ntest_label  = y_test","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:28:42.087427Z","iopub.execute_input":"2022-07-20T12:28:42.088456Z","iopub.status.idle":"2022-07-20T12:28:42.094445Z","shell.execute_reply.started":"2022-07-20T12:28:42.088420Z","shell.execute_reply":"2022-07-20T12:28:42.092670Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Preparing the sentences\ndef data_prep_fct(bert_tokenizer, sentences, max_length) :\n    \n    input_ids=[]\n    attention_masks=[]\n    token_type_ids=[]\n    segment_ids=[]\n\n    for sent in sentences:\n        bert_inp = bert_tokenizer.encode_plus(sent,\n                                              add_special_tokens = True,\n                                              max_length = max_length,\n                                              padding='max_length',\n                                              truncation=True,\n                                              return_attention_mask = True, \n                                              return_token_type_ids=True)\n        input_ids.append(bert_inp['input_ids'])\n        attention_masks.append(bert_inp['attention_mask'])\n        token_type_ids.append(bert_inp['token_type_ids'])\n        segment_id = [0] * max_length\n        segment_ids.append(segment_id)\n\n    input_ids = np.asarray(input_ids)\n    attention_masks = np.array(attention_masks)\n    token_type_ids = np.array(token_type_ids)\n    segment_ids = np.array(segment_ids)\n    \n#     return input_ids, attention_masks\n    return input_ids, attention_masks, token_type_ids, segment_ids","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:28:48.706230Z","iopub.execute_input":"2022-07-20T12:28:48.706691Z","iopub.status.idle":"2022-07-20T12:28:48.718615Z","shell.execute_reply.started":"2022-07-20T12:28:48.706656Z","shell.execute_reply":"2022-07-20T12:28:48.716919Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_test_prep_fct(bert_tokenizer) :\n\n    print(\"Train tweets preparation ...\")\n    sentences = tweet_raw_train\n    start = time.time()\n    train_inp, train_mask, train_token, train_seg = data_prep_fct(\n        bert_tokenizer,\n        sentences,\n        max_length=max_length\n    )\n    print(\"duration: \", time.time()-start)\n    print()\n\n    print(\"Test tweets preparation ...\")\n    sentences = tweet_raw_test\n    start = time.time()\n    test_inp, test_mask, test_token, test_seg = data_prep_fct(\n        bert_tokenizer,\n        sentences,\n        max_length=max_length\n    )\n    print(\"duration: \", time.time()-start)\n    \n    return train_inp, train_mask,train_token,train_seg, test_inp, test_mask,test_token, test_seg","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:28:55.481057Z","iopub.execute_input":"2022-07-20T12:28:55.481583Z","iopub.status.idle":"2022-07-20T12:28:55.492093Z","shell.execute_reply.started":"2022-07-20T12:28:55.481549Z","shell.execute_reply":"2022-07-20T12:28:55.490198Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_name = 'bert'\n\nmodel_type   = 'hkayesh/twitter-disaster-nlp'\n#'finiteautomata/bertweet-base-sentiment-analysis'\n\nmax_length   = 64\nbert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n#AutoTokenizer.from_pretrained(model_type)\n\nmt = (model_type.split('-')[0][0] + model_type.split('-')[1][0] + model_type.split('-')[2][0]).upper()\nml = 'ML' + str(max_length)\ntw = 'T' + str(len(tweets_raw))\nmodel_file_name = model_name + '_' + mt + '_' + ml + '_' + tw\nmodel_save_path = model_file_name + '.h5'\n# = path + 'models/' + model_file_name + '.h5'\nprint(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:24.701995Z","iopub.execute_input":"2022-07-20T11:43:24.702585Z","iopub.status.idle":"2022-07-20T11:43:27.138394Z","shell.execute_reply.started":"2022-07-20T11:43:24.702558Z","shell.execute_reply":"2022-07-20T11:43:27.137386Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"train_inp, train_mask, train_token, train_seg, test_inp, test_mask, test_token, test_seg = \\\n                                                                train_test_prep_fct(bert_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:27.139791Z","iopub.execute_input":"2022-07-20T11:43:27.140233Z","iopub.status.idle":"2022-07-20T11:43:28.603348Z","shell.execute_reply.started":"2022-07-20T11:43:27.140192Z","shell.execute_reply":"2022-07-20T11:43:28.602190Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"train_inp.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:28.604745Z","iopub.execute_input":"2022-07-20T11:43:28.605636Z","iopub.status.idle":"2022-07-20T11:43:28.614705Z","shell.execute_reply.started":"2022-07-20T11:43:28.605593Z","shell.execute_reply":"2022-07-20T11:43:28.613709Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"bert_model = TFBertForSequenceClassification.from_pretrained(model_type, num_labels=2)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08 ) \nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n\n\nbert_model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\nprint(bert_model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:28.616093Z","iopub.execute_input":"2022-07-20T11:43:28.616620Z","iopub.status.idle":"2022-07-20T11:43:30.013794Z","shell.execute_reply.started":"2022-07-20T11:43:28.616577Z","shell.execute_reply":"2022-07-20T11:43:30.012590Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n                                                    save_weights_only=True,\n                                                    monitor='val_loss',mode='min',\n                                                    save_best_only=True, verbose=1)\ncallbacks = [es, mc]\n\nhistory = bert_model.fit(\n                         [train_inp, train_mask, train_seg], train_label,                         \n                         batch_size=4, epochs=3 ,\n                         validation_data=([test_inp, test_mask, test_seg],test_label),\n                         callbacks=callbacks, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:43:30.015096Z","iopub.execute_input":"2022-07-20T11:43:30.015947Z","iopub.status.idle":"2022-07-20T11:50:05.781759Z","shell.execute_reply.started":"2022-07-20T11:43:30.015906Z","shell.execute_reply":"2022-07-20T11:50:05.780665Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"trained_model = bert_model\ntrained_model.save_weights(model_save_path)\ntrained_model.load_weights(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:05.783509Z","iopub.execute_input":"2022-07-20T11:50:05.783922Z","iopub.status.idle":"2022-07-20T11:50:07.236364Z","shell.execute_reply.started":"2022-07-20T11:50:05.783880Z","shell.execute_reply":"2022-07-20T11:50:07.235349Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:07.237859Z","iopub.execute_input":"2022-07-20T11:50:07.238202Z","iopub.status.idle":"2022-07-20T11:50:07.243857Z","shell.execute_reply.started":"2022-07-20T11:50:07.238166Z","shell.execute_reply":"2022-07-20T11:50:07.242673Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = trained_model.predict([test_inp, test_mask, test_seg], batch_size=4)[0][:,1]\ny_pred = np.where(y_pred_proba>0,1,0)\nprint(\"accuracy : \", metrics.accuracy_score(y_test,y_pred))\nprint(\"auc      : \", metrics.roc_auc_score(y_test,y_pred_proba))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:07.245572Z","iopub.execute_input":"2022-07-20T11:50:07.246279Z","iopub.status.idle":"2022-07-20T11:50:22.321571Z","shell.execute_reply.started":"2022-07-20T11:50:07.246242Z","shell.execute_reply":"2022-07-20T11:50:22.320404Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresh = metrics.roc_curve(y_test,y_pred_proba)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=\"BERT, AUC=\"+str(round(auc,4)))\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random guess')\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.323237Z","iopub.execute_input":"2022-07-20T11:50:22.323574Z","iopub.status.idle":"2022-07-20T11:50:22.521585Z","shell.execute_reply.started":"2022-07-20T11:50:22.323538Z","shell.execute_reply":"2022-07-20T11:50:22.520705Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"markdown","source":"### New code","metadata":{}},{"cell_type":"code","source":"train = train.sample(frac=1).reset_index()\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.523059Z","iopub.execute_input":"2022-07-20T11:50:22.523323Z","iopub.status.idle":"2022-07-20T11:50:22.537670Z","shell.execute_reply.started":"2022-07-20T11:50:22.523299Z","shell.execute_reply":"2022-07-20T11:50:22.536673Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"train_sentences = train[\"text\"]\nlabels = train[\"target\"]\ntest_sentences = test[\"text\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.538954Z","iopub.execute_input":"2022-07-20T11:50:22.539379Z","iopub.status.idle":"2022-07-20T11:50:22.546657Z","shell.execute_reply.started":"2022-07-20T11:50:22.539341Z","shell.execute_reply":"2022-07-20T11:50:22.545614Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"def data_prep_fct_1(bert_tokenizer, sentences, max_length=128) :\n    \n    input_ids=[]\n    attention_masks=[]\n    token_type_ids=[]\n    segment_ids=[]\n\n    for sent in sentences:\n        bert_inp = bert_tokenizer.encode_plus(sent,\n                                              add_special_tokens = True,\n                                              max_length = max_length,\n                                              truncation=True,\n                                              pad_to_max_length = True,\n                                              return_attention_mask = True, \n                                              return_token_type_ids=True)\n        input_ids.append(bert_inp['input_ids'])\n        attention_masks.append(bert_inp['attention_mask'])\n\n    input_ids = np.asarray(input_ids)\n    attention_masks = np.array(attention_masks)\n    \n    return input_ids, attention_masks","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.547939Z","iopub.execute_input":"2022-07-20T11:50:22.549050Z","iopub.status.idle":"2022-07-20T11:50:22.558643Z","shell.execute_reply.started":"2022-07-20T11:50:22.549013Z","shell.execute_reply":"2022-07-20T11:50:22.557627Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# ModÃ¨le\nmodel_name    = 'bert'\nmodel_type = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\ndo_lower_case = True\nmax_length   = 64\n# Train_test_split\ntest_size    = 0.2\nrandom_state = 5\n\n# Hyperparameters of Model\nlearning_rate = 1e-5\nepsilon=1e-08\nbatch_size = 4","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.559994Z","iopub.execute_input":"2022-07-20T11:50:22.560730Z","iopub.status.idle":"2022-07-20T11:50:22.568785Z","shell.execute_reply.started":"2022-07-20T11:50:22.560671Z","shell.execute_reply":"2022-07-20T11:50:22.567885Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"roberta_tokenizer = AutoTokenizer.from_pretrained(model_type, do_lower_case=do_lower_case)\nstart = time.time()\ninput_ids, attention_masks = data_prep_fct_1(roberta_tokenizer, train_sentences, max_length=max_length)\nprint(\"duration : \", time.time()-start)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:22.570181Z","iopub.execute_input":"2022-07-20T11:50:22.570768Z","iopub.status.idle":"2022-07-20T11:50:27.981146Z","shell.execute_reply.started":"2022-07-20T11:50:22.570726Z","shell.execute_reply":"2022-07-20T11:50:27.979324Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"train_inp, val_inp, train_label, val_label, train_mask, val_mask = \\\n    train_test_split(input_ids, labels, attention_masks,\n                     stratify=labels, test_size=test_size, random_state=random_state)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:27.982818Z","iopub.execute_input":"2022-07-20T11:50:27.983203Z","iopub.status.idle":"2022-07-20T11:50:27.997110Z","shell.execute_reply.started":"2022-07-20T11:50:27.983165Z","shell.execute_reply":"2022-07-20T11:50:27.996078Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\nmodel_save_path = 'RoBerta_cardiff.h5'\nroberta_model = TFRobertaForSequenceClassification.from_pretrained(model_type,num_labels=2)\ncallbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n                                                save_weights_only=True,\n                                                monitor='val_loss',mode='min',\n                                                save_best_only=True, verbose=1)]\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n\nroberta_model.compile(loss=loss,optimizer=optimizer,metrics=[metric])\nprint(roberta_model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:27.999249Z","iopub.execute_input":"2022-07-20T11:50:27.999675Z","iopub.status.idle":"2022-07-20T11:50:29.596202Z","shell.execute_reply.started":"2022-07-20T11:50:27.999637Z","shell.execute_reply":"2022-07-20T11:50:29.595136Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"history = roberta_model.fit(\n    [train_inp,train_mask], train_label,\n    batch_size=batch_size, epochs=1,\n    validation_data=([val_inp,val_mask],val_label),\n    callbacks=callbacks, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:50:29.597902Z","iopub.execute_input":"2022-07-20T11:50:29.598268Z","iopub.status.idle":"2022-07-20T11:52:48.926492Z","shell.execute_reply.started":"2022-07-20T11:50:29.598223Z","shell.execute_reply":"2022-07-20T11:52:48.925219Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"start = time.time()\ntest_input_ids, test_attention_masks = data_prep_fct_1(roberta_tokenizer, test_sentences, max_length=max_length)\nprint(\"Test Sentences preparation duration : \", time.time()-start)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:52:48.932137Z","iopub.execute_input":"2022-07-20T11:52:48.932957Z","iopub.status.idle":"2022-07-20T11:52:49.550861Z","shell.execute_reply.started":"2022-07-20T11:52:48.932913Z","shell.execute_reply":"2022-07-20T11:52:49.549772Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"predictions = roberta_model.predict([test_input_ids,test_attention_masks])","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:52:49.552589Z","iopub.execute_input":"2022-07-20T11:52:49.552982Z","iopub.status.idle":"2022-07-20T11:53:00.930661Z","shell.execute_reply.started":"2022-07-20T11:52:49.552944Z","shell.execute_reply":"2022-07-20T11:53:00.929650Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = predictions[0][:,1]\ny_pred = np.where(y_pred_proba>0,1,0)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:53:00.932557Z","iopub.execute_input":"2022-07-20T11:53:00.933273Z","iopub.status.idle":"2022-07-20T11:53:00.939797Z","shell.execute_reply.started":"2022-07-20T11:53:00.933225Z","shell.execute_reply":"2022-07-20T11:53:00.938857Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame(data={\"id\":test.id, \"target\":y_pred})\noutput.to_csv(\"submission.csv\", index=False, quoting=3)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T11:53:00.941516Z","iopub.execute_input":"2022-07-20T11:53:00.941966Z","iopub.status.idle":"2022-07-20T11:53:00.958450Z","shell.execute_reply.started":"2022-07-20T11:53:00.941922Z","shell.execute_reply":"2022-07-20T11:53:00.957585Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"markdown","source":"### test roberta ","metadata":{}},{"cell_type":"code","source":"model_name = 'roberta_V2'\nmodel_type   = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\nmax_length   = 64\nroberta_V2_tokenizer = AutoTokenizer.from_pretrained(model_type)\n\n\nmt = (model_type.split('-')[0][0] + model_type.split('-')[1][0] + model_type.split('-')[2][0]).upper()\nml = 'ML' + str(max_length)\ntw = 'T' + str(len(tweets_raw))\nmodel_file_name = model_name + '_' + mt + '_' + ml + '_' + tw\nmodel_save_path = model_file_name + '.h5'\nprint(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:29:12.656377Z","iopub.execute_input":"2022-07-20T12:29:12.656820Z","iopub.status.idle":"2022-07-20T12:29:20.911527Z","shell.execute_reply.started":"2022-07-20T12:29:12.656787Z","shell.execute_reply":"2022-07-20T12:29:20.909668Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_inp, train_mask, train_token, train_seg, test_inp, test_mask, test_token, test_seg = \\\n                                                                train_test_prep_fct(roberta_V2_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:29:49.934716Z","iopub.execute_input":"2022-07-20T12:29:49.935169Z","iopub.status.idle":"2022-07-20T12:29:52.199316Z","shell.execute_reply.started":"2022-07-20T12:29:49.935136Z","shell.execute_reply":"2022-07-20T12:29:52.197869Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"roberta_V2_model = TFRobertaForSequenceClassification.from_pretrained(model_type,num_labels=2)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08 ) \nmetric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\nroberta_V2_model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\nprint(roberta_V2_model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:32:08.388268Z","iopub.execute_input":"2022-07-20T12:32:08.389428Z","iopub.status.idle":"2022-07-20T12:32:57.702439Z","shell.execute_reply.started":"2022-07-20T12:32:08.389378Z","shell.execute_reply":"2022-07-20T12:32:57.700963Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n                                                    save_weights_only=True,\n                                                    monitor='val_loss',mode='min',\n                                                    save_best_only=True, verbose=1)\ncallbacks = [es, mc]\n\nhistory = roberta_V2_model.fit(\n    [train_inp, train_mask, train_seg], train_label,\n    batch_size=4, epochs=1,\n    validation_data=([test_inp, test_mask, test_seg],test_label),\n    callbacks=callbacks, verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:33:52.231861Z","iopub.execute_input":"2022-07-20T12:33:52.232269Z","iopub.status.idle":"2022-07-20T12:37:42.622339Z","shell.execute_reply.started":"2022-07-20T12:33:52.232237Z","shell.execute_reply":"2022-07-20T12:37:42.620630Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trained_model = roberta_V2_model\ntrained_model.save_weights(model_save_path)\ntrained_model.load_weights(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:38:37.044771Z","iopub.execute_input":"2022-07-20T12:38:37.045210Z","iopub.status.idle":"2022-07-20T12:38:39.463860Z","shell.execute_reply.started":"2022-07-20T12:38:37.045177Z","shell.execute_reply":"2022-07-20T12:38:39.462396Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = trained_model.predict([test_inp, test_mask, test_seg], batch_size=4)[0][:,1]\ny_pred = np.where(y_pred_proba>0,1,0)\nprint(\"accuracy : \", metrics.accuracy_score(y_test,y_pred))\nprint(\"auc      : \", metrics.roc_auc_score(y_test,y_pred_proba))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:39:17.424728Z","iopub.execute_input":"2022-07-20T12:39:17.425165Z","iopub.status.idle":"2022-07-20T12:39:42.000105Z","shell.execute_reply.started":"2022-07-20T12:39:17.425133Z","shell.execute_reply":"2022-07-20T12:39:41.998689Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresh = metrics.roc_curve(y_test,y_pred_proba)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=\"RoBERTa, AUC=\"+str(round(auc,4)))\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random guess')\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:40:05.622936Z","iopub.execute_input":"2022-07-20T12:40:05.623419Z","iopub.status.idle":"2022-07-20T12:40:05.950176Z","shell.execute_reply.started":"2022-07-20T12:40:05.623372Z","shell.execute_reply":"2022-07-20T12:40:05.948686Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred, labels=np.unique(y_pred)))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T12:53:40.980286Z","iopub.execute_input":"2022-07-20T12:53:40.980751Z","iopub.status.idle":"2022-07-20T12:53:41.001733Z","shell.execute_reply.started":"2022-07-20T12:53:40.980717Z","shell.execute_reply":"2022-07-20T12:53:41.000302Z"},"trusted":true},"execution_count":23,"outputs":[]}]}