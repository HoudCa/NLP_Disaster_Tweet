# Kaggle competition: Natural Language Processing with Disaster Tweets
Dans ce projet, nous ferons une analyse des sentiments coupl√©e √† l'apprentissage automatique afin de d√©tecter les tweets de catastrophe de Twitter. Le
but est de d√©terminer s'il y a une v√©ritable catastrophe ou non d'apr√®s le tweet.
Pour cela, nous avons d'utilis√© deux mod√®les pr√©-entrain√©s BERT, RoBERTa et √©valuer leurs performances respectives en examinant la pr√©cision et l'aire sous
la courbe ROC.

# Les donn√©es
Le jeu de donn√©es utilis√© est issu de la comp√©tition Kaggle [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started).
Il est r√©parti en 7613 tweets pour la formation et 3263 tweets pour la validation.
Il contient les 6 champs suivants :

1. id : Un identifiant unique pour chaque tweet,
2. text : Le texte du tweet,
3. keyword : Un mot-cl√© du tweet (bien qu'il puisse √™tre vide !),
4. location : L'emplacement d'o√π le tweet a √©t√© envoy√© (peut √©galement √™tre
vide),
5. target : Indique si un tweet concerne une v√©ritable catastrophe (1) ou
non (0), seulement dans les fichiers train.csv et sample_submission.csv

Dans le jeu de donn√©es pour la formation, il y 57% de tweets annon√ßant une catastrophe.

Nous avons divis√© notre jeu de donn√©es en un ensemble de donn√©es d'entrainement et de validation en utilisant train_test_split. Nous utiliserons 80% de l'ensemble de 
donn√©es comme donn√©es d'apprentissage et √©valuerons les performances sur les 20% restantes.

# √âvaluation des performances
La partie √©valuation de notre travail utilise l'√©valuateur Kaggle. L'√©valuation se compose de 3263 tweet non labellis√©s que nous classons avec chacun de
nos mod√®les. Nos simulations ont montr√© que RoBERTa atteint des meilleurs performances que BERT. En eet, la pr√©cision (accuracy) de 83% et dont l'aire
sous la courbe ROC (AUC) est de 89% contre une pr√©cision de 57% et une AUC de 68% pour le mod√®le BERT.
